# ðŸ¤– 05 - Machine Learning Algorithms

This section covers a comprehensive range of machine learning algorithms from linear models to advanced ensemble methods.

## Topics Covered

### Linear Models
- **Simple Linear Regression** (`simple-linear-regression/`) - Single variable regression
- **Multiple Linear Regression** (`multiple-linear-regression/`) - Multiple variables regression
- **Polynomial Regression** (`polynomial-regression/`) - Non-linear relationships
- **Regularized Models** (`regularized-linear-models/`) - Ridge, Lasso, Elastic Net
- **Lasso Regression** (`lasso-regression/`) - L1 regularization
- **Elastic Net** (`elasticnet-regression/`) - Combined L1 and L2 regularization

### Classification
- **Logistic Regression** (`logistic-regression/`) - Binary and multiclass classification
- **Advanced Logistic Regression** (`logistic-regression-continued/`) - Softmax, polynomial features
- **K-Nearest Neighbors** (`knn/`) - Instance-based learning
- **Support Vector Machines** (`svm/`) - Maximum margin classifiers

### Tree-Based Methods
- **Random Forest** (`random-forest/`) - Ensemble of decision trees
- **Bagging** (`bagging/`) - Bootstrap aggregating
- **AdaBoost** (`adaboost/`) - Adaptive boosting
- **Gradient Boosting** (`gradient-boosting/`) - Gradient-based boosting

### Ensemble Methods
- **Voting Classifier** (`voting-classifier/`) - Hard and soft voting
- **Stacking and Blending** (`stacking-and-blending/`) - Advanced ensemble techniques

### Clustering (Unsupervised Learning)
- **K-Means** (`kmeans/`) - Partition-based clustering
- **DBSCAN** (`dbscan/`) - Density-based clustering

### Special Topics
- **Imbalanced Data** (`imbalanced-data/`) - Handling class imbalance

## Learning Objectives

By the end of this section, you will be able to:
- âœ… Implement various regression and classification algorithms
- âœ… Understand when to use different algorithms
- âœ… Tune hyperparameters effectively
- âœ… Build ensemble models
- âœ… Apply clustering algorithms
- âœ… Handle imbalanced datasets

## Prerequisites

- Completed `04-feature-engineering/`
- Understanding of train/test split
- Basic knowledge of model evaluation

## Estimated Time

**20-30 hours** (this is the largest section - take your time!)

## Key Concepts

- **Bias-Variance Tradeoff**: Understanding model complexity
- **Overfitting vs Underfitting**: Regularization techniques
- **Ensemble Methods**: Combining multiple models for better performance
- **Hyperparameter Tuning**: Grid search, random search

## Algorithm Selection Guide

- **Linear Models**: Good baseline, interpretable, fast
- **Tree-Based**: Handles non-linear relationships, feature importance
- **Ensemble**: Best performance, but less interpretable
- **SVM**: Good for high-dimensional data
- **KNN**: Simple, good for small datasets

## Next Steps

After completing this section, move to:
- **`06-model-evaluation/`** - Learn how to properly evaluate your models

---

**Happy Learning!** ðŸš€
