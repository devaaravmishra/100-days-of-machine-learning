# ğŸš€ 100 Days of Machine Learning

A comprehensive collection of machine learning concepts, implementations, and hands-on projects covering everything from data preprocessing to advanced algorithms and model evaluation.

## ğŸ“‹ Table of Contents

-   [Overview](#overview)
-   [Learning Path](#learning-path)
-   [Data Handling & Preprocessing](#data-handling--preprocessing)
-   [Exploratory Data Analysis](#exploratory-data-analysis)
-   [Feature Engineering](#feature-engineering)
-   [Machine Learning Algorithms](#machine-learning-algorithms)
-   [Model Evaluation & Metrics](#model-evaluation--metrics)
-   [Advanced Topics](#advanced-topics)
-   [Getting Started](#getting-started)
-   [Project Structure](#project-structure)
-   [Contributing](#contributing)

## ğŸ¯ Overview

This repository contains a structured learning journey through machine learning concepts, organized into logical modules. Each module includes:

-   **Jupyter Notebooks** with step-by-step implementations
-   **Real-world datasets** for hands-on practice
-   **Visualizations** and interactive demos
-   **Code examples** from scratch and using scikit-learn
-   **Mathematical explanations** with practical applications

## ğŸ›¤ï¸ Learning Path

### Phase 1: Data Fundamentals

1. **Data Sources & Formats** â†’ **Data Preprocessing** â†’ **Exploratory Analysis**

### Phase 2: Feature Engineering

1. **Encoding Techniques** â†’ **Scaling & Normalization** â†’ **Feature Selection**

### Phase 3: Machine Learning Core

1. **Linear Models** â†’ **Tree-based Methods** â†’ **Ensemble Techniques**

### Phase 4: Advanced Topics

1. **Clustering** â†’ **Dimensionality Reduction** â†’ **Model Optimization**

---

## ğŸ“Š Data Handling & Preprocessing

### Data Sources

-   **`csv-files/`** - Working with CSV files, different separators, and data loading techniques
-   **`json-and-sql/`** - JSON data handling and SQL integration
-   **`api-to-dataframe/`** - Converting API responses to pandas DataFrames
-   **`pandas-dataframe-web-scraping/`** - Web scraping and data extraction

### Data Cleaning & Missing Values

-   **`complete-case-analysis/`** - Complete case analysis for missing data
-   **`imputing-numerical-data/`** - Mean, median, and arbitrary value imputation
-   **`handling-missing-categorical-data/`** - Frequent value and missing category imputation
-   **`missing-indicator/`** - Missing value indicators and random sample imputation
-   **`knn-imputer/`** - K-Nearest Neighbors imputation
-   **`iterative-imputer/`** - Iterative imputation techniques

### Data Types & Mixed Variables

-   **`handling-mixed-variables/`** - Working with mixed data types
-   **`handling-date-and-time/`** - Date and time feature engineering

---

## ğŸ” Exploratory Data Analysis

### Statistical Analysis

-   **`descriptive-stats/`** - Understanding your data with descriptive statistics
-   **`univariate-analysis/`** - Single variable analysis and distributions
-   **`bivariate-analysis/`** - Two-variable relationships and correlations
-   **`pandas-profiling/`** - Automated EDA with pandas profiling

### Outlier Detection & Treatment

-   **`outlier-removal-zscore/`** - Z-score based outlier detection
-   **`outlier-removal-iqr/`** - Interquartile Range (IQR) method
-   **`outlier-detection-percentiles/`** - Percentile-based outlier detection

---

## âš™ï¸ Feature Engineering

### Encoding Techniques

-   **`ordinal-encoding/`** - Ordinal categorical encoding
-   **`one-hot-encoding/`** - One-hot encoding for categorical variables
-   **`binning-and-binarization/`** - Feature binning and binarization

### Scaling & Normalization

-   **`standardization/`** - Z-score standardization
-   **`normalization/`** - Min-max normalization
-   **`power-transformer/`** - Power and Box-Cox transformations

### Advanced Feature Engineering

-   **`feature-construction-and-splitting/`** - Creating and splitting features
-   **`function-transformer/`** - Custom function transformations
-   **`column-transformer/`** - Column-wise transformations
-   **`sklearn-pipelines/`** - End-to-end ML pipelines

---

## ğŸ¤– Machine Learning Algorithms

### Linear Models

-   **`simple-linear-regression/`** - Single variable linear regression
-   **`multiple-linear-regression/`** - Multiple variable linear regression
-   **`polynomial-regression/`** - Polynomial feature regression
-   **`regularized-linear-models/`** - Ridge, Lasso, and Elastic Net
-   **`lasso-regression/`** - Lasso regression implementation
-   **`elasticnet-regression/`** - Elastic Net regression

### Classification

-   **`logistic-regression/`** - Logistic regression fundamentals
-   **`logistic-regression-continued/`** - Advanced logistic regression topics

### Tree-Based Methods

-   **`random-forest/`** - Random Forest implementation and analysis
-   **`adaboost/`** - AdaBoost algorithm and hyperparameter tuning
-   **`gradient-boosting/`** - Gradient Boosting implementation

### Ensemble Methods

-   **`stacking-and-blending/`** - Model stacking and blending techniques

### Clustering

-   **`kmeans/`** - K-Means clustering with interactive demos

---

## ğŸ“ˆ Model Evaluation & Metrics

### Regression Metrics

-   **`regression-metrics/`** - MAE, MSE, RMSE, RÂ², and more

### Classification Metrics

-   **`classification-metrics/`** - Accuracy, Precision, Recall, F1-Score, ROC-AUC

---

## ğŸ§® Mathematical Foundations

### Optimization

-   **`gradient-descent/`** - Gradient descent from scratch with animations
-   **`types-of-gradient-descent/`** - Batch, Stochastic, and Mini-batch GD

### Dimensionality Reduction

-   **`pca/`** - Principal Component Analysis

---

## ğŸš€ Advanced Topics

### Model Optimization

-   **`sklearn-pipelines/`** - Complete ML pipeline implementation
-   **`stacking-and-blending/`** - Advanced ensemble techniques

---

## ğŸ› ï¸ Getting Started

### Prerequisites

```bash
pip install pandas numpy matplotlib seaborn scikit-learn jupyter
```

### Running the Notebooks

1. Clone the repository
2. Navigate to any topic folder
3. Open the Jupyter notebook
4. Run the cells to see the implementation

### Recommended Learning Order

1. Start with **Data Handling & Preprocessing** modules
2. Move to **Exploratory Data Analysis**
3. Learn **Feature Engineering** techniques
4. Implement **Machine Learning Algorithms**
5. Master **Model Evaluation & Metrics**
6. Explore **Advanced Topics**

---

## ğŸ“ Project Structure

```
100-days-of-machine-learning/
â”œâ”€â”€ ğŸ“Š Data Handling & Preprocessing/
â”‚   â”œâ”€â”€ csv-files/                    # CSV data manipulation
â”‚   â”œâ”€â”€ json-and-sql/                 # JSON and SQL integration
â”‚   â”œâ”€â”€ api-to-dataframe/             # API data conversion
â”‚   â”œâ”€â”€ pandas-dataframe-web-scraping/ # Web scraping
â”‚   â”œâ”€â”€ complete-case-analysis/        # Missing data analysis
â”‚   â”œâ”€â”€ imputing-numerical-data/       # Numerical imputation
â”‚   â”œâ”€â”€ handling-missing-categorical-data/ # Categorical imputation
â”‚   â”œâ”€â”€ missing-indicator/             # Missing value indicators
â”‚   â”œâ”€â”€ knn-imputer/                   # KNN imputation
â”‚   â”œâ”€â”€ iterative-imputer/             # Iterative imputation
â”‚   â”œâ”€â”€ handling-mixed-variables/      # Mixed data types
â”‚   â””â”€â”€ handling-date-and-time/        # Date/time features
â”‚
â”œâ”€â”€ ğŸ” Exploratory Data Analysis/
â”‚   â”œâ”€â”€ descriptive-stats/             # Statistical summaries
â”‚   â”œâ”€â”€ univariate-analysis/           # Single variable analysis
â”‚   â”œâ”€â”€ bivariate-analysis/            # Two variable analysis
â”‚   â”œâ”€â”€ pandas-profiling/              # Automated EDA
â”‚   â”œâ”€â”€ outlier-removal-zscore/        # Z-score outliers
â”‚   â”œâ”€â”€ outlier-removal-iqr/           # IQR outliers
â”‚   â””â”€â”€ outlier-detection-percentiles/ # Percentile outliers
â”‚
â”œâ”€â”€ âš™ï¸ Feature Engineering/
â”‚   â”œâ”€â”€ ordinal-encoding/              # Ordinal encoding
â”‚   â”œâ”€â”€ one-hot-encoding/              # One-hot encoding
â”‚   â”œâ”€â”€ binning-and-binarization/      # Feature binning
â”‚   â”œâ”€â”€ standardization/               # Z-score scaling
â”‚   â”œâ”€â”€ normalization/                 # Min-max scaling
â”‚   â”œâ”€â”€ power-transformer/             # Power transformations
â”‚   â”œâ”€â”€ feature-construction-and-splitting/ # Feature creation
â”‚   â”œâ”€â”€ function-transformer/          # Custom transformations
â”‚   â”œâ”€â”€ column-transformer/            # Column transformations
â”‚   â””â”€â”€ sklearn-pipelines/             # ML pipelines
â”‚
â”œâ”€â”€ ğŸ¤– Machine Learning Algorithms/
â”‚   â”œâ”€â”€ simple-linear-regression/      # Linear regression
â”‚   â”œâ”€â”€ multiple-linear-regression/    # Multiple regression
â”‚   â”œâ”€â”€ polynomial-regression/         # Polynomial regression
â”‚   â”œâ”€â”€ regularized-linear-models/     # Regularized models
â”‚   â”œâ”€â”€ lasso-regression/              # Lasso regression
â”‚   â”œâ”€â”€ elasticnet-regression/         # Elastic Net
â”‚   â”œâ”€â”€ logistic-regression/           # Logistic regression
â”‚   â”œâ”€â”€ logistic-regression-continued/ # Advanced logistic regression
â”‚   â”œâ”€â”€ random-forest/                 # Random Forest
â”‚   â”œâ”€â”€ adaboost/                      # AdaBoost
â”‚   â”œâ”€â”€ gradient-boosting/             # Gradient Boosting
â”‚   â”œâ”€â”€ stacking-and-blending/         # Ensemble methods
â”‚   â””â”€â”€ kmeans/                        # K-Means clustering
â”‚
â”œâ”€â”€ ğŸ“ˆ Model Evaluation/
â”‚   â”œâ”€â”€ regression-metrics/            # Regression evaluation
â”‚   â””â”€â”€ classification-metrics/        # Classification evaluation
â”‚
â”œâ”€â”€ ğŸ§® Mathematical Foundations/
â”‚   â”œâ”€â”€ gradient-descent/              # Gradient descent
â”‚   â”œâ”€â”€ types-of-gradient-descent/     # GD variants
â”‚   â””â”€â”€ pca/                           # Principal Component Analysis
â”‚
â””â”€â”€ ğŸ“š Additional Resources/
    â”œâ”€â”€ adaboost_demo.ipynb            # AdaBoost demonstration
    â””â”€â”€ README.md                      # This file
```

---

## ğŸ¯ Key Features

-   **ğŸ“š Comprehensive Coverage**: From basic data handling to advanced ML algorithms
-   **ğŸ”¬ Hands-on Learning**: Interactive Jupyter notebooks with real datasets
-   **ğŸ“Š Visual Learning**: Rich visualizations and animations (especially in gradient descent)
-   **ğŸ› ï¸ Practical Implementation**: Both from-scratch and scikit-learn implementations
-   **ğŸ“ˆ Real-world Applications**: Industry-standard datasets and use cases
-   **ğŸ¨ Interactive Demos**: Streamlit apps and interactive visualizations

---

## ğŸš€ Quick Start Examples

### Data Loading

```python
import pandas as pd
df = pd.read_csv('your_data.csv')
```

### Basic EDA

```python
import matplotlib.pyplot as plt
df.describe()
df.hist()
plt.show()
```

### Machine Learning Pipeline

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
model = RandomForestClassifier()
model.fit(X_train, y_train)
```

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to:

-   Add new machine learning topics
-   Improve existing implementations
-   Fix bugs or enhance documentation
-   Add more datasets or examples

---

## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

---

## ğŸ™ Acknowledgments

-   **[CampusX YouTube Playlist](https://www.youtube.com/playlist?list=PLKnIA16_Rmvbr7zKYQuBfsVkjoLcJgxHH)** - 100 Days of Machine Learning course that inspired this repository
-   Scikit-learn community for excellent documentation
-   Pandas team for powerful data manipulation tools
-   Matplotlib and Seaborn for visualization capabilities
-   The machine learning community for continuous learning and sharing

---

**Happy Learning! ğŸ‰**
